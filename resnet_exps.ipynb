{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from loguru import logger\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from src.cifar_autoencoder import CifarDataSet, AutoEncoder, train\n",
    "from src.cifar_graph_classifier_optimized import Net\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.resnet_encoder import ResnetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pranjal/pytorch/Datasets/cifar-10-batches-py/data_batch_*\n"
     ]
    }
   ],
   "source": [
    "# train_ds = CifarDataSet(\n",
    "#             batch_dir_path=\"/home/pranjal/pytorch/Datasets\", mode=\"train\"\n",
    "#         )\n",
    "# test_ds = CifarDataSet(\n",
    "#             batch_dir_path=\"/home/pranjal/pytorch/Datasets\", mode=\"test\"\n",
    "#         )\n",
    "sample_ds = CifarDataSet(\n",
    "            batch_dir_path=\"/home/pranjal/pytorch/Datasets\", mode=\"sample\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/pranjal/.cache/torch/hub/pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "r = ResnetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dl = DataLoader(sample_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "for data, label in _dl:\n",
    "    resp = r.encoder(data)\n",
    "    print(resp.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(layers_hidden_units,):\n",
    "    layers_list = []\n",
    "    for clu, nlu in zip(\n",
    "        layers_hidden_units[:-1], layers_hidden_units[1:-1]\n",
    "    ):\n",
    "        print(clu,nlu)\n",
    "        layers_list.extend(\n",
    "            [\n",
    "                nn.Linear(in_features=clu, out_features=nlu),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=0.8),\n",
    "                nn.BatchNorm1d(num_features=nlu),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    layers_list.append(\n",
    "        nn.Linear(\n",
    "            in_features=layers_hidden_units[-2],\n",
    "            out_features=layers_hidden_units[-1],\n",
    "        ),\n",
    "    )\n",
    "    return layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 128\n",
      "128 256\n",
      "256 512\n",
      "512 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=1024, out_features=128, bias=True),\n",
       " ReLU(),\n",
       " Dropout(p=0.8, inplace=False),\n",
       " BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=128, out_features=256, bias=True),\n",
       " ReLU(),\n",
       " Dropout(p=0.8, inplace=False),\n",
       " BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=256, out_features=512, bias=True),\n",
       " ReLU(),\n",
       " Dropout(p=0.8, inplace=False),\n",
       " BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=512, out_features=1024, bias=True),\n",
       " ReLU(),\n",
       " Dropout(p=0.8, inplace=False),\n",
       " BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Linear(in_features=1024, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_layers([1024,128,256,512,1024,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.denselayers = nn.Sequential(\n",
    "        #     nn.Linear(in_features=1024, out_features=128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(p=self.keep_prob),\n",
    "        #     nn.BatchNorm1d(num_features=128),\n",
    "        #     nn.Linear(in_features=128, out_features=256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(p=self.keep_prob),\n",
    "        #     nn.BatchNorm1d(num_features=256),\n",
    "        #     nn.Linear(in_features=256, out_features=512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(p=self.keep_prob),\n",
    "        #     nn.BatchNorm1d(num_features=512),\n",
    "        #     nn.Linear(in_features=512, out_features=1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Dropout(p=self.keep_prob),\n",
    "        #     nn.BatchNorm1d(num_features=1024),\n",
    "        #     nn.Linear(in_features=1024, out_features=10),\n",
    "        # ).to(self.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('gcn': conda)",
   "language": "python",
   "name": "python38564bitgcncondacb855bff8b454c0bbae31f8183fac245"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
